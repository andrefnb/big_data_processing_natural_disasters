# big_data_processing_natural_disasters
Master's Degree in Big Data analysis and engeneering. Assignment 1 of the Systems for Big Data Processing course.

To succeed in this project, you must create the requested indexes using three different technologies
(over Apache Hadoop):

    1. Create a Map-Reduce program to create the three indexes;
    
    2. Create a Spark program to create the three indexes;
    
    3. Create a Spark DataFrame or SparkSQL program to create the three indexes.

You are being asked to create three indexes for answering the following three queries:

    1. How many disasters occurred in continent C? (columns 5 and 9);

    2. In which regions there were disasters of type X? (columns 3 and 6);

    3. What are the probabilities of getting injured or dying in a natural disaster of type T in the continent C
    during decade D (190x, 191x, 192x, ..., 199x, 200x, 201x)? (columns 0, 3, 5, 10, 11, and 14);

    4. An optional 4 th index that will answer a non-trivial and interesting question over the given data
    set. If you add this to your project you will get some extra points.
